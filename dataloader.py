import cv2
import torch
import os

import pandas as pd
from torch.utils.data import Dataset, DataLoader
from dataclasses import dataclass


def read_video_frames(video_path, max_frames=None):
    frames_dict = {}
    cap = cv2.VideoCapture(video_path)
    frame_count = 0

    while cap.isOpened():
        ret, frame = cap.read()
        if not ret:
            break

        # BGR -> RGB ë³€í™˜, float32 ì •ê·œí™” í›„ í…ì„œë¡œ ë³€í™˜
        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        frame_tensor = (
            torch.from_numpy(frame).permute(2, 0, 1).float() / 255.0
        )  # (3, H, W)
        frames_dict[frame_count] = frame_tensor

        frame_count += 1
        if max_frames and frame_count >= max_frames:
            break

    cap.release()

    return frames_dict


@dataclass
class IVQAConfig:
    data_root: str = "/hub_data2/intern/jinwoo/iVQA"
    video_dir: str = "videos"
    annotation_file: str = "ivqa.csv"
    train_csv: str = "train.csv"
    val_csv: str = "val.csv"
    test_csv: str = "test.csv"

    def get_video_path(self, video_id, start, end):
        filename = f"{video_id}_{int(start)}_{int(end)}.webm"
        return os.path.join(self.data_root, self.video_dir, filename)


ivqa_config = IVQAConfig()


class iVQADataset(Dataset):
    def __init__(self, config: IVQAConfig = ivqa_config):
        """
        Args:
            csv_path (str): path to train.csv, val.csv, or test.csv
            video_dir (str): path to directory containing video files (optional)
            return_video (bool): whether to return video filepath (or only metadata)
        """
        csv_path = os.path.join(config.data_root, config.annotation_file)
        video_dir = os.path.join(config.data_root, config.video_dir)

        self.df = pd.read_csv(csv_path)
        self.video_dir = video_dir

    def __len__(self):
        return len(self.df)

    def __getitem__(self, idx):
        row = self.df.iloc[idx]

        # Core components
        question = row["question"]
        answers = [row[f"answer{i}"] for i in range(1, 6)]
        confs = [row[f"conf{i}"] for i in range(1, 6)]

        # Video metadata
        video_id = row["video_id"]
        start = row["start"]
        end = row["end"]
        video_path = os.path.join(self.video_dir, f"{video_id}_{start}_{end}.webm")

        frames = read_video_frames(video_path)

        sample = {
            "question": question,
            "answers": answers,
            "confs": confs,
            "video_id": video_id,
            "start": start,
            "end": end,
            "video_path": video_path,
            "frames": frames,  # ì´ ë¶€ë¶„ ì¶”ê°€ë¨
        }

        return sample


class iVQADataloader:
    def __init__(self, config: IVQAConfig = ivqa_config, batch_size=1, shuffle=False):
        self.dataset = iVQADataset(config)
        self.batch_size = batch_size
        self.shuffle = shuffle

    def get_loader(self):
        return DataLoader(
            self.dataset, batch_size=self.batch_size, shuffle=self.shuffle
        )


if __name__ == "__main__":
    # ì„¤ì •
    config = IVQAConfig()
    dataloader_wrapper = iVQADataloader(config=config, batch_size=1, shuffle=True)
    loader = dataloader_wrapper.get_loader()

    # í•˜ë‚˜ì˜ ë°°ì¹˜ë§Œ í™•ì¸
    for batch in loader:
        question = batch["question"]
        answers = batch["answers"]
        video_id = batch["video_id"]
        frames = batch["frames"]  # dict í˜•íƒœ

        print(f"ğŸŸ¡ Video ID: {video_id}")
        print(f"ğŸ”¹ Question: {question}")
        print(f"ğŸ”¸ Answers: {answers}")
        break

    # í”„ë ˆì„ ì‹œê°í™” (ìµœëŒ€ 3ê°œ)
